{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# iris.data\n",
    "# iris.target\n",
    "# iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   type  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['type'] = iris.target\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним количество одинаковых значений для разных классов у признаков **sepal length (cm)** и **petal width (cm)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(iris_df.loc[iris_df.type == 0, 'sepal length (cm)'].values) & \n",
    "    set(iris_df.loc[iris_df.type == 1, 'sepal length (cm)'].values)) + \\\n",
    "len(set(iris_df.loc[iris_df.type == 1, 'sepal length (cm)'].values) & \n",
    "    set(iris_df.loc[iris_df.type == 2, 'sepal length (cm)'].values)) + \\\n",
    "len(set(iris_df.loc[iris_df.type == 0, 'sepal length (cm)'].values) & \n",
    "    set(iris_df.loc[iris_df.type == 2, 'sepal length (cm)'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(iris_df.loc[iris_df.type == 0, 'petal width (cm)'].values) & \n",
    "    set(iris_df.loc[iris_df.type == 1, 'petal width (cm)'].values)) + \\\n",
    "len(set(iris_df.loc[iris_df.type == 1, 'petal width (cm)'].values) & \n",
    "    set(iris_df.loc[iris_df.type == 2, 'petal width (cm)'].values)) + \\\n",
    "len(set(iris_df.loc[iris_df.type == 0, 'petal width (cm)'].values) & \n",
    "    set(iris_df.loc[iris_df.type == 2, 'petal width (cm)'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество одинаковых значений у признака **sepal length (cm)** больше, чем у признака **petal width (cm)**, поэтому прогноз дерева решений по признаку **sepal length (cm)** будет хуже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_ginni(l):\n",
    "    return sum([(x / len(l))* (1 - x / len(l)) for x in Counter(l).values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_entropy(l):\n",
    "    return -sum([(x / len(l)) * np.log2(x / len(l)) for x in Counter(l).values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decision_tree_classification:\n",
    "    \"\"\"\n",
    "    Реализует процесс построения дерева решений с помощью одномерного разбиения \n",
    "    Принимает в качестве параметров:\n",
    "    1) значения одного признака\n",
    "    2) значения классов\n",
    "    3) функцию для вычисления критерия информативности\n",
    "    4) глубину дерева решений\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y, f, n): \n",
    "        df = pd.DataFrame({'x': x, 'y': y}).sort_values(by='x')\n",
    "        self.x = df.x.values\n",
    "        self.y = df.y.values\n",
    "        self.f = f\n",
    "        self.n = n\n",
    "    \n",
    "    def node_select(self, y, f):\n",
    "        \"\"\"\n",
    "        Разбивает массив y на подмножества по критерию информативности,\n",
    "        вычисленному с помощью функции f\n",
    "        \"\"\"\n",
    "        treshold1 = 0\n",
    "        treshold2 = 0\n",
    "        igr0 = 0\n",
    "        hr = f(y)\n",
    "        for i in range(len(y) - 1):\n",
    "            for j in range(i + 1, len(y)):\n",
    "                hr0 = f(y[:i])\n",
    "                hr1 = f(y[i:j])\n",
    "                hr2 = f(y[j:])\n",
    "                igr = hr - (len(y[:i]) / len(y)) * hr0 - (len(y[i:j]) / len(y)) * hr1 - (len(y[j:]) / len(y)) * hr2\n",
    "                if np.round(igr0, 4) <= np.round(igr, 4):\n",
    "                    igr0 = igr\n",
    "                    treshold1 = i\n",
    "                    treshold2 = j\n",
    "            if len(np.unique(y)) == 2 and i == 0:\n",
    "                break\n",
    "        return igr0, treshold1, treshold2\n",
    "    \n",
    "    def classifier(self):\n",
    "        \"\"\"\n",
    "        Возвращает индексы узлов в отсортированном массиве значений признака, по которому\n",
    "        строится дерево решений, полученных при заданной глубине дерева, либо когда функционал\n",
    "        качества будет равен 0 для всех узлов\n",
    "        \"\"\"\n",
    "        nodes = [self.y]\n",
    "        nodes_temp = []\n",
    "        end_nodes = []\n",
    "        threshold_prev = [0]\n",
    "        threshold = []\n",
    "        stop_criteria = 0\n",
    "\n",
    "        for i in range(self.n):\n",
    "            for j, nodes[j] in zip(range(len(nodes)), nodes):\n",
    "                igr, t1, t2 = self.node_select(nodes[j], self.f)\n",
    "                if igr != 0:\n",
    "                    threshold.append(threshold_prev[j])\n",
    "                    if t1 != 0:\n",
    "                        threshold.append(threshold_prev[j] + t1)\n",
    "                    threshold.append(threshold_prev[j] + t2)\n",
    "                    if t1 != 0:\n",
    "                        nodes_temp.append(nodes[j][:t1])\n",
    "                    nodes_temp.append(nodes[j][t1:t2])\n",
    "                    nodes_temp.append(nodes[j][t2:])\n",
    "                    if i == self.n - 1 and len(nodes[j]) > 1:\n",
    "                        end_nodes.append(threshold_prev[j])\n",
    "                else:\n",
    "                    end_nodes.append(threshold_prev[j])\n",
    "\n",
    "                stop_criteria += igr\n",
    "\n",
    "            if stop_criteria == 0:\n",
    "                break\n",
    "\n",
    "            stop_criteria = 0\n",
    "            threshold_prev = threshold\n",
    "            threshold = []\n",
    "            nodes = nodes_temp\n",
    "            nodes_temp = []\n",
    "\n",
    "        return sorted(list(set(end_nodes)))\n",
    "    \n",
    "    def prediction(self, x_test):\n",
    "        \"\"\"\n",
    "        Возвращает массив с предсказанными метками класса\n",
    "        \"\"\"\n",
    "        predicted = []\n",
    "        nodes = self.classifier()\n",
    "        for el in x_test:\n",
    "            for i in range(len(nodes)):\n",
    "                if i != 0:\n",
    "                    if i != len(nodes) - 1:\n",
    "                        if self.x[nodes[i]] <= el < self.x[nodes[i + 1]]:\n",
    "                            predicted.append(self.y[nodes[i + 1] - 1])\n",
    "                    else:\n",
    "                        if el >= self.x[nodes[i]]:\n",
    "                            predicted.append(self.y[nodes[i]])\n",
    "                else:\n",
    "                    if el < self.x[nodes[i + 1]]:\n",
    "                        predicted.append(self.y[nodes[i + 1] - 1])\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним точность модели для разных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_class = decision_tree_classification(X_train[:, 3], y_train, h_ginni, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted1 = dt_class.prediction(X_test[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree metrics for 'petal width' attribute\n",
      "accuracy: 0.967\n",
      "precision: 0.970\n",
      "recall: 0.967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(\"Decision tree metrics for 'petal width' attribute\")\n",
    "print('accuracy: %.3f' % accuracy_score(y_test, predicted1))\n",
    "print('precision: %.3f' % precision_score(y_test, predicted1, average='weighted'))\n",
    "print('recall: %.3f' % recall_score(y_test, predicted1, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_class = decision_tree_classification(X_train[:, 0], y_train, h_ginni, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted2 = dt_class.prediction(X_test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree metrics for 'sepal length' attribute\n",
      "accuracy: 0.500\n",
      "precision: 0.576\n",
      "recall: 0.500\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision tree metrics for 'sepal length' attribute\")\n",
    "print('accuracy: %.3f' % accuracy_score(y_test, predicted2))\n",
    "print('precision: %.3f' % precision_score(y_test, predicted2, average='weighted'))\n",
    "print('recall: %.3f' % recall_score(y_test, predicted2, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
